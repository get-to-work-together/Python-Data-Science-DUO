import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns





url = 'https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv'


df = pd.read_csv(url, index_col=0)
df.head()





df = sns.load_dataset('penguins')
df.head()





df.info()


sns.pairplot(df, hue='species')





df['species'].unique()


df['species'] = df['species'].astype('category')


df['species'].value_counts()





df.dropna(inplace = True)


df.info()





from sklearn.preprocessing import OneHotEncoder


categorical_features = ['island','sex']


df[categorical_features] = df[categorical_features].astype('category')


dummies = pd.get_dummies(df[categorical_features], dtype = 'int', drop_first = True)
dummies


df = pd.concat([df, dummies], axis = 1)


enc = OneHotEncoder()

enc.fit(df[categorical_features] )

onehotlabels = enc.transform(df[categorical_features]).toarray()

onehotlabels


enc.categories_


encoded_columns = list(enc.get_feature_names_out(['island', 'sex']))
encoded_columns


df[encoded_columns] = onehotlabels


df





feature_names = ['bill_length_mm',
                 'bill_depth_mm',
                 'flipper_length_mm',
                 'body_mass_g',
                 # 'sex_Female'
                 'sex_Male',
                 # 'island_Biscoe', 
                 # 'island_Dream', 
                 # 'island_Torgersen'
                ]
target_name = 'species'

print('features:', feature_names)
print('target:', target_name)





from sklearn.model_selection import train_test_split


# np.random.seed(1234)

df_train, df_test = train_test_split(df, test_size = 0.3)

print('df_train', df_train.shape)
print('df_test', df_test.shape)


df_train['species'].value_counts()


df_train_features = df_train[feature_names]
df_train_target = df_train[target_name]
df_test_features = df_test[feature_names]
df_test_target = df_test[target_name]





from sklearn.preprocessing import StandardScaler, MinMaxScaler


scaler = MinMaxScaler()

scaler.fit(df_train_features)

train_features_scaled = scaler.transform(df_train_features)
test_features_scaled = scaler.transform(df_test_features)

print('mean', round(train_features_scaled.mean(), 10))
print('std', train_features_scaled.std())
print('min', train_features_scaled.min())
print('max', train_features_scaled.max())

print('train_features_scaled', train_features_scaled.shape)
print('test_features_scaled', test_features_scaled.shape)


train_features_scaled.round(2)


df_train_features_scaled = pd.DataFrame(train_features_scaled, 
                                        columns = [col + '_scaled' for col in list(df_train_features.columns)], 
                                        index = df_train_features.index)


df_test_features_scaled = pd.DataFrame(test_features_scaled, 
                                       columns = [col + '_scaled' for col in list(df_test_features.columns)], 
                                       index = df_test_features.index)





df_train = pd.concat([df_train_features,
                      df_train_features_scaled,
                      df_train_target], axis=1)


df_test = pd.concat([df_test_features,
                     df_test_features_scaled,
                     df_test_target], axis=1)


df_train





df_train.to_csv('../datasets/penguins_training_dataset.csv')
df_test.to_csv('../datasets/penguins_test_dataset.csv')








from sklearn.neighbors import KNeighborsClassifier


classifier = KNeighborsClassifier(n_neighbors = 3)

classifier.fit(df_train_features_scaled, df_train_target)


predicted = classifier.predict(df_test_features_scaled)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


from sklearn.metrics import accuracy_score

accuracy_score(predicted, df_test_target)


df_test['3NN_predicted'] = predicted
df_test['3NN_correct'] = correct


df_test


df_test[df_test['3NN_correct']==False]





classifier = KNeighborsClassifier(n_neighbors = 5)

classifier.fit(df_train_features_scaled, df_train_target)


predicted = classifier.predict(df_test_features_scaled)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


df_test['5NN_predicted'] = predicted
df_test['5NN_correct'] = correct


df_test[df_test['5NN_correct']==False]





classifier = KNeighborsClassifier(n_neighbors = 5)

classifier.fit(df_train_features_scaled, df_train_target)


predicted = classifier.predict(df_test_features_scaled)
correct = predicted == df_test_target


correct.value_counts()


df_test['5NN_predicted'] = predicted
df_test['5NN_correct'] = correct


df_test[df_test['5NN_correct']==False].head()





from sklearn.naive_bayes import GaussianNB


classifier = GaussianNB()

classifier.fit(df_train_features, df_train_target)


predicted = classifier.predict(df_test_features)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


accuracy = accuracy_score(df_test_target, predicted)

accuracy


df_test['NB_predicted'] = predicted
df_test['NB_correct'] = correct


df_test[df_test['NB_correct']==False]





from sklearn.tree import DecisionTreeClassifier


classifier = DecisionTreeClassifier(max_depth=4)

classifier.fit(df_train_features, df_train_target)


predicted = classifier.predict(df_test_features)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


df_test['DT_predicted'] = predicted
df_test['DT_correct'] = correct


df_test[df_test['DT_correct']==False]


from sklearn.tree import plot_tree

plt.figure(figsize = (15,10))

plot_tree(classifier, 
          feature_names = feature_names,
          class_names = target_name,
          filled = True,
          rounded = True, 
          impurity = False)

plt.show()


from sklearn.tree import export_text

print(export_text(classifier, 
                  feature_names = feature_names))


print('Feature Importances Decision Tree', classifier.feature_importances_)





from sklearn.ensemble import RandomForestClassifier


classifier = RandomForestClassifier(n_estimators = 100)

classifier.fit(df_train_features, df_train_target)


predicted = classifier.predict(df_test_features)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


df_test['RF_predicted'] = predicted
df_test['RF_correct'] = correct


df_test[df_test['RF_correct']==False]


print('Feature Importances Random Forest', classifier.feature_importances_)





from sklearn.svm import SVC


classifier = SVC(kernel = 'rbf')

classifier.fit(df_train_features, df_train_target)


predicted = classifier.predict(df_test_features)
correct = predicted == df_test_target


correct.value_counts().values[0]


try:
    n_correct, n_incorrect = correct.value_counts().values
except ValueError:
    n_correct = correct.value_counts().values[0]
    n_incorrect = 0
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


df_test['SVM_predicted'] = predicted
df_test['SVM_correct'] = correct


df_test[df_test['SVM_correct']==False]





from sklearn.linear_model import LogisticRegression


classifier = LogisticRegression(random_state=0, max_iter=1000)

classifier.fit(df_train_features, df_train_target)


predicted = classifier.predict(df_test_features)
correct = predicted == df_test_target


correct.value_counts()


n_correct, n_incorrect = correct.value_counts().values
accuracy = n_correct / (n_correct + n_incorrect)
accuracy


df_test['LR_predicted'] = predicted
df_test['LR_correct'] = correct


df_test[df_test['LR_correct']==False]


(classifier.coef_.round(2)[2] * np.array([46.0, 18.9, 195.0, 4150.0])).sum()





from sklearn.neural_network import MLPClassifier


classifier = MLPClassifier(solver='lbfgs',
                               activation='relu',     #'logistic',
                               alpha=1e-5,
                               hidden_layer_sizes=(5, 5), 
                               random_state=1,
                               max_iter=10000)

classifier.fit(df_train_features_scaled, df_train_target)


predicted = classifier.predict(df_test_features_scaled)
correct = predicted == df_test_target


correct.value_counts()


try:
    n_correct, n_incorrect = correct.value_counts().values
    accuracy = n_correct / (n_correct + n_incorrect)
except:
    accuracy = 1.0
accuracy


df_test['MLP_predicted'] = predicted
df_test['MLP_correct'] = correct


df_test[df_test['MLP_correct']==False]





prediction = '5NN_predicted'





from sklearn.metrics import confusion_matrix


cm = confusion_matrix(df_test_target, df_test[prediction])
cm





from sklearn.metrics import accuracy_score


accuracy = accuracy_score(df_test_target, df_test[prediction])

print('accuracy:', accuracy)





from sklearn.metrics import precision_recall_fscore_support


precision, recall, f_score, _ = precision_recall_fscore_support(df_test_target, df_test[prediction])

print('precision:', precision)
print('recall:', recall)
print('f-score:', f_score)





def print_metrics(target, predicted, labels = ('Adelie', 'Gentoo', 'Chinstrap')):
    conf = confusion_matrix(target, predicted)
    accuracy = accuracy_score(target, predicted)
    precision, recall, f_score, num_case = precision_recall_fscore_support(target, predicted)
    print('Confusion matrix')
    print()
    print('               %20s %20s %20s' % tuple('Predicted ' + label for label in labels))
    print('Actual %-12s     %6d               %5d                    %5d' % (labels[0:1] + tuple(conf[0])))
    print('Actual %-12s     %6d               %5d                    %5d' % (labels[1:2] + tuple(conf[1])))
    print('Actual %-12s     %6d               %5d                    %5d' % (labels[2:3] + tuple(conf[2])))
    print()
    print('Accuracy  %0.2f' % accuracy)
    print()
    print('               %20s %20s %20s' % tuple(labels))
    print('Num case       %20d %20d %20d' % tuple(num_case))
    print('Precision      %20.2f %20.2f %20.2f' % tuple(precision))
    print('Recall         %20.2f %20.2f %20.2f' % tuple(recall))
    print('F1             %20.2f %20.2f %20.2f' % tuple(f_score))


print('\n3-Nearest Neighbor **************************************************************\n')
print_metrics(df_test[target_name], df_test['3NN_predicted'])   

print('\nNaive Bayes *********************************************************************\n')
print_metrics(df_test[target_name], df_test['NB_predicted'])   

print('\nDecision Tree *******************************************************************\n')
print_metrics(df_test[target_name], df_test['DT_predicted'])   

print('\nRandom Forest *******************************************************************\n')
print_metrics(df_test[target_name], df_test['RF_predicted'])   

print('\nLogistic Regression **************************************************************\n')
print_metrics(df_test[target_name], df_test['LR_predicted'])   

print('\nMulti-Layer Perceptron / Neural Network ******************************************\n')
print_metrics(df_test[target_name], df_test['MLP_predicted'])  








from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.ensemble import GradientBoostingClassifier

classifiers = [
    {'name': '3NN', 'classifier': KNeighborsClassifier,       'kwargs': {'n_neighbors': 3}},
    {'name': '5NN', 'classifier': KNeighborsClassifier,       'kwargs': {'n_neighbors': 5}},
    {'name': 'DT',  'classifier': DecisionTreeClassifier,     'kwargs': {'max_depth': 4}},
    {'name': 'RF',  'classifier': RandomForestClassifier,     'kwargs': {'n_estimators': 100}},
    {'name': 'NB',  'classifier': GaussianNB,                 'kwargs': {}},
    {'name': 'SVM', 'classifier': SVC,                        'kwargs': {'kernel': 'rbf'}},
    {'name': 'LG',  'classifier': LogisticRegression,         'kwargs': {'max_iter': 1000}},
    {'name': 'MLP', 'classifier': MLPClassifier,              'kwargs': {'activation': 'relu', 'hidden_layer_sizes': (5, 5), 'solver': 'lbfgs', 'max_iter': 1000}},
    {'name': 'GBM', 'classifier': GradientBoostingClassifier, 'kwargs': {}},
]

results = []
for d in classifiers:
    classifier = d['classifier'](**d['kwargs'])
    classifier.fit(df_train_features_scaled, df_train_target)
    predicted = classifier.predict(df_test_features_scaled)
    correct = predicted == df_test_target

    df_test[f"{d['name']}_predicted"] = predicted
    df_test[f"{d['name']}_correct"] = correct
    
    cm = confusion_matrix(df_test_target, predicted)
    accuracy = accuracy = accuracy_score(df_test_target, predicted)
    precision, recall, f_score, *_ = precision_recall_fscore_support(df_test_target, predicted)

    metrics = {}
    metrics['name'] = d['name']
    metrics['confusion_matrix'] = cm
    metrics['accuracy'] = accuracy
    metrics['precision'] = precision
    metrics['recall'] = recall
    metrics['f_score'] = f_score

    results.append(metrics)


df_results = pd.DataFrame(results)
df_results


pd.concat([df_results[['name', 'accuracy']], 
           pd.DataFrame(df_results['precision'].to_list(), columns = df['species'].unique()).add_prefix('precision_'), 
           pd.DataFrame(df_results['recall'].to_list(), columns = df['species'].unique()).add_prefix('recall_'), 
           pd.DataFrame(df_results['f_score'].to_list(), columns = df['species'].unique()).add_prefix('f_score_')], axis = 1)



