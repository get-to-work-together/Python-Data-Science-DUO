


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns





df = sns.load_dataset('penguins')
df.head()





df.info()


sns.pairplot(df, hue='species');





df.dropna(inplace = True)


df.info()





target = 'species'

numeric_features = [
    'bill_length_mm', 
    'bill_depth_mm',
    'flipper_length_mm', 
    'body_mass_g', 
]

categorical_features = [
    'island', 
    'sex'
]

features = numeric_features + categorical_features





df[target].value_counts()


df[target] = df[target].astype('category')


df_target = df[target]





df_dummy_variables = pd.get_dummies(df[categorical_features], dtype='int', drop_first=True)
df_dummy_variables


df_features = pd.concat([df[numeric_features], df_dummy_variables], axis=1)
df_features





from sklearn.model_selection import train_test_split


df_target_train, df_target_test, df_features_train, df_features_test = \
    train_test_split(df_target, df_features, test_size = 0.3, random_state = 12345)

print('df_target_train', df_target_train.shape)
print('df_target_test', df_target_test.shape)
print('df_features_train', df_features_train.shape)
print('df_features_test', df_features_test.shape)





from sklearn.preprocessing import StandardScaler, MinMaxScaler


scaler = MinMaxScaler()

scaler.fit(df_features_train)

train_features_scaled = scaler.transform(df_features_train)
test_features_scaled = scaler.transform(df_features_test)

print('mean', round(train_features_scaled.mean(), 10))
print('std', train_features_scaled.std())
print('min', train_features_scaled.min())
print('max', train_features_scaled.max())


df_features_train_scaled = pd.DataFrame(train_features_scaled, 
                                        columns = [col + '_scaled' for col in list(df_features_train.columns)], 
                                        index = df_features_train.index)


df_features_test_scaled = pd.DataFrame(test_features_scaled, 
                                       columns = [col + '_scaled' for col in list(df_features_test.columns)], 
                                       index = df_features_test.index)








from sklearn.neighbors import KNeighborsClassifier


classifier = KNeighborsClassifier(n_neighbors = 3)

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)
print(f'{n_correct} of {n_total} correct')


accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





classifier = KNeighborsClassifier(n_neighbors = 5)

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)
print(f'{n_correct} of {n_total} correct')


accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





classifier = KNeighborsClassifier(n_neighbors = 5)

classifier.fit(df_features_train, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)
print(f'{n_correct} of {n_total} correct')


accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





from sklearn.naive_bayes import GaussianNB


classifier = GaussianNB()

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





from sklearn.tree import DecisionTreeClassifier


classifier = DecisionTreeClassifier(max_depth=3)

classifier.fit(df_features_train, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')


from sklearn.tree import plot_tree

plt.figure(figsize = (15,10))

plot_tree(classifier, 
          feature_names = df_features_train.columns,
          class_names = df_target_train.unique(),
          filled = True,
          rounded = True, 
          impurity = False)

plt.show()


from sklearn.tree import export_text

print(export_text(classifier, 
                  feature_names = df_features_train.columns))


print('Feature Importances Decision Tree', classifier.feature_importances_)


print('Feature Importances Decision Tree')
for k, v in zip( df_features_train.columns, classifier.feature_importances_):
    print(f'{k:20}: {v:.2f}')





from sklearn.ensemble import RandomForestClassifier


classifier = RandomForestClassifier(n_estimators = 100)

classifier.fit(df_features_train, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')


print('Feature Importances Decision Tree')
for k, v in zip( df_features_train.columns, classifier.feature_importances_):
    print(f'{k:20}: {v:.2f}')





from sklearn.linear_model import LogisticRegression


classifier = LogisticRegression(random_state=0, max_iter=1000)

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')


classifier.coef_.round(2)





from sklearn.svm import SVC


classifier = SVC(kernel = 'rbf')

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





from sklearn.neural_network import MLPClassifier


classifier = MLPClassifier(solver='lbfgs',
                               activation='relu',     #'logistic',
                               alpha=1e-5,
                               hidden_layer_sizes=(5, 5), 
                               random_state=1,
                               max_iter=10000)

classifier.fit(df_features_train_scaled, df_target_train)


actual = df_target_test.values
predicted = classifier.predict(df_features_test_scaled)

correct = predicted == actual

n_correct = np.sum(correct)
n_total = len(actual)

accuracy = n_correct / n_total

print(f'Accuracy: {accuracy}')





prediction = '5NN_predicted'





from sklearn.metrics import confusion_matrix


cm = confusion_matrix(df_target_test, predicted)
cm





from sklearn.metrics import accuracy_score


accuracy = accuracy_score(df_target_test, predicted)

print('accuracy:', accuracy)





from sklearn.metrics import precision_recall_fscore_support


precision, recall, f_score, _ = precision_recall_fscore_support(df_target_test, predicted)

print('precision:', precision)
print('recall:', recall)
print('f-score:', f_score)





def print_metrics(name, target, predicted, labels = ('Adelie', 'Gentoo', 'Chinstrap')):
    conf = confusion_matrix(target, predicted)
    accuracy = accuracy_score(target, predicted)
    precision, recall, f_score, num_case = precision_recall_fscore_support(target, predicted)
    
    print(80 * '=')
    print()
    print(name)
    print()
    print('Confusion matrix')
    print()
    print('                %20s %20s %20s' % tuple('Predicted ' + label for label in labels))
    print('Actual %-12s           %6d               %6d               %6d' % (labels[0:1] + tuple(conf[0])))
    print('Actual %-12s           %6d               %6d               %6d' % (labels[1:2] + tuple(conf[1])))
    print('Actual %-12s           %6d               %6d               %6d' % (labels[2:3] + tuple(conf[2])))
    print()
    print('Accuracy  %0.2f' % accuracy)
    print()
    print('                %20s %20s %20s' % tuple(labels))
    print('Number of cases %20d %20d %20d' % tuple(num_case))
    print('Precision       %20.2f %20.2f %20.2f' % tuple(precision))
    print('Recall          %20.2f %20.2f %20.2f' % tuple(recall))
    print('F1              %20.2f %20.2f %20.2f' % tuple(f_score))
    print()


def classify(name, classifier, df_features_train, df_target_train, df_features_test, df_target_test):
    classifier.fit(df_features_train, df_target_train)

    actual = df_target_test.values
    predicted = classifier.predict(df_features_test)
    
    print_metrics(name, actual, predicted)


classifiers = {
    '3 Nearest Neighbor': KNeighborsClassifier(n_neighbors = 3),
    '5 Nearest Neighbor': KNeighborsClassifier(n_neighbors = 5),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier(max_depth=3),
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression(random_state=0, max_iter=1000),
    'Support Vector Machine': SVC(kernel = 'rbf'),
    'Multi Layer Perceptron': MLPClassifier(hidden_layer_sizes=(5, 5), activation='relu', solver='lbfgs', max_iter=10000)
}

for name, classifier in classifiers.items():
    classify(name, 
             classifier, 
             df_features_train_scaled, 
             df_target_train, 
             df_features_test_scaled, 
             df_target_test)









